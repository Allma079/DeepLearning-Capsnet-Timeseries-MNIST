{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pre-processes the raw financial data in order to create a matrix of prices/volume. This matrix is then 'read' by the network. <br>\n",
    "For each period of time, the program takes the 30 previous value to create the tensor using:\n",
    "- Open\n",
    "- High\n",
    "- Low\n",
    "- Close\n",
    "- Volumne\n",
    "\n",
    "Each serie is batch-normalized using mean and standard-deviation.\n",
    "\n",
    "The matrix shape is (30,5) corresponding to (time period, number of input prices + volume). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:55:08.809839Z",
     "start_time": "2018-06-03T21:55:08.799593Z"
    }
   },
   "outputs": [],
   "source": [
    "#for navigation in the folders\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from time import strptime\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "from time import strftime\n",
    "\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation in folders and building of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part gets all the stocks' token included into the folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:08.538775Z",
     "start_time": "2018-06-03T21:51:08.519433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 505 different stocks.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/sandp500/individual_stocks_5yr/'\n",
    "directory = os.getcwd() + data_dir # path to the files\n",
    "files_tags = os.listdir(directory) #these are the differents pdf files\n",
    "\n",
    "#this is here because hidden files are also shown in the list. \n",
    "for file in files_tags:\n",
    "    if file[0] == '.':\n",
    "        files_tags.remove(file)\n",
    "stock_name = [file.split('_')[0] for file in files_tags]\n",
    "stocks = [file for file in files_tags]\n",
    "print('There are {} different stocks.'.format(len(stock_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting and stopping date of each stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different stocks start and end at different time. This part removes the stocks which are not entirely in the biggest time span. (starting on the 2013-02-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:09.163390Z",
     "start_time": "2018-06-03T21:51:09.158569Z"
    }
   },
   "outputs": [],
   "source": [
    "df_start_end = pd.DataFrame(columns = ['stock', 'start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:11.615312Z",
     "start_time": "2018-06-03T21:51:09.347705Z"
    }
   },
   "outputs": [],
   "source": [
    "name = list()\n",
    "start=list()\n",
    "end = list()\n",
    "\n",
    "for s in stocks:\n",
    "    df = pd.read_csv(os.getcwd() + data_dir + s)\n",
    "    name.append(df.Name.iloc[0])\n",
    "    start.append(df.date.iloc[0])\n",
    "    end.append(df.date.iloc[-1])\n",
    "df_start_end.stock = name\n",
    "df_start_end.start = start\n",
    "df_start_end.end = end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T19:29:53.039308Z",
     "start_time": "2018-04-22T19:29:53.018480Z"
    }
   },
   "source": [
    "## Get the time span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:11.708897Z",
     "start_time": "2018-06-03T21:51:11.703913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2018-02-07'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date = set(df_start_end.end)\n",
    "end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the stocks have the same 'end'. So there is no 'early stopping' stocks. There is no need to remove any stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:11.830745Z",
     "start_time": "2018-06-03T21:51:11.820841Z"
    }
   },
   "outputs": [],
   "source": [
    "starting_list = list(set(df_start_end.start))\n",
    "starting_dict = {key: 0 for key in list(set(df_start_end.start))}\n",
    "for i in df_start_end.start:\n",
    "    for j in starting_list:\n",
    "        if i == j:\n",
    "            starting_dict[j]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T04:21:59.863790Z",
     "start_time": "2018-06-04T04:21:59.859665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014-03-27': 1, '2015-01-02': 1, '2015-06-24': 1, '2017-09-01': 1, '2014-07-31': 1, '2014-06-19': 1, '2015-07-06': 2, '2016-01-05': 1, '2013-06-13': 1, '2017-07-03': 1, '2013-06-19': 4, '2017-01-04': 1, '2013-05-09': 1, '2013-02-08': 476, '2015-10-19': 2, '2014-04-17': 1, '2013-11-18': 1, '2015-11-16': 1, '2017-12-05': 1, '2016-07-01': 1, '2016-04-07': 1, '2017-07-17': 1, '2017-04-03': 1, '2014-09-24': 1, '2016-12-02': 1}\n"
     ]
    }
   ],
   "source": [
    "print(starting_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the stocks were already started at the beginning of the time span.  <br>\n",
    "We will only take these stocks for our study. (starting date: 2013-02-08) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:51:14.439037Z",
     "start_time": "2018-06-03T21:51:12.071595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:02<00:00, 214.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for s in tqdm(stocks):\n",
    "    data = pd.read_csv(os.getcwd() + data_dir + s)\n",
    "    count += data.isnull().sum().sum()\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-22T21:22:09.357182Z",
     "start_time": "2018-04-22T21:22:09.349504Z"
    }
   },
   "source": [
    "We have only 27 nan values, let's remove them by taking the back value. <br>\n",
    "This is done by the '.fillna('bfill')' method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the datasets stock by stock. So we don't take into account full length stock/not full length stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:54:01.522381Z",
     "start_time": "2018-06-03T21:51:14.538800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [02:46<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "kept_stocks = list()\n",
    "not_kept_stocks = list()\n",
    "\n",
    "#tqdm is a package which enables to visualize the progress bar\n",
    "for s in tqdm(stocks):\n",
    "    \n",
    "    data = pd.read_csv(os.getcwd() + data_dir + s).fillna('bfill')\n",
    "    name = s.split('_')[0]\n",
    "    \n",
    "    #function located in the utils file \n",
    "    #it returns an array of matrixes (each matrix is the input of the network) from the stocks' time series\n",
    "    X, Y = get_X_Y(data)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    \n",
    "    \n",
    "    #function located in the utils file \n",
    "    #it splits the train, test and validation sets\n",
    "    #the splitting is not random \n",
    "    #it is made with respect of the time line\n",
    "    #train -> test -> validation\n",
    "    X_train, X_test, X_val, Y_train, Y_val, Y_test = create_Xt_Yt(X, Y, \n",
    "                                                                  percentage_train=0.8, percentage_val = 0.1, percentage_test = 0.1)\n",
    "    \n",
    "    #this line checks if there is any nan in the matrixes\n",
    "    count = (np.isnan(X_train).sum() + np.isnan(X_test).sum() + np.isnan(X_val).sum()\n",
    "             + np.isnan(Y_train).sum() + np.isnan(Y_val).sum() + np.isnan(Y_test).sum())\n",
    "    \n",
    "    if count>0:\n",
    "        print('error nan', s)\n",
    "        \n",
    "    #it takes only the stocks which correspond to the whole time span \n",
    "    if X_train.shape!=(982,30,5):\n",
    "        not_kept_stocks.append(s)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        kept_stocks.append(s)\n",
    "        \n",
    "        #each stock is stored in a different folder\n",
    "        out_path_stock = '/data_out_autoreg/'+name+'/'\n",
    "        out_directory = os.getcwd() + out_path_stock\n",
    "        #create folder\n",
    "        pathlib.Path(out_directory).mkdir(parents=True, exist_ok=True) \n",
    "        \n",
    "        \n",
    "        #each matrix is saved with numpy function\n",
    "        np.save(out_directory+'Y_train', Y_train)\n",
    "        np.save(out_directory+'Y_val', Y_val)\n",
    "        np.save(out_directory+'Y_test', Y_test)\n",
    "        np.save(out_directory+'X_train', X_train)\n",
    "        np.save(out_directory+'X_val', X_val)\n",
    "        np.save(out_directory+'X_test', X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:54:01.679984Z",
     "start_time": "2018-06-03T21:54:01.672777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of kept stocks is: 468 .\n"
     ]
    }
   ],
   "source": [
    "print('The number of kept stocks is:', len(kept_stocks),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T21:54:01.868625Z",
     "start_time": "2018-06-03T21:54:01.864290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of not kept stocks is: 37 .\n"
     ]
    }
   ],
   "source": [
    "print('The number of not kept stocks is:', len(not_kept_stocks),'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the data are pre-processed to be used as input by the neural network. <br>\n",
    "The input of this code is a set of 5 time series (Open, High, Low, Close, Volume) which is turned into batch-normalized matrix of shape (30,5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
